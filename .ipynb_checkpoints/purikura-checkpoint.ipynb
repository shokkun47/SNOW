{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7acb3bc3-b7b7-4f68-8453-a3a5b22dc075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "\n",
    "# DNNベースの顔検出器のロード\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "landmark_predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "# 特定領域の処理を行うための関数\n",
    "def apply_transformation(roi, fx=1.0, fy=1.0):\n",
    "    # 領域を指定された倍率でリサイズ\n",
    "    resized_roi = cv2.resize(roi, None, fx=fx, fy=fy)\n",
    "    return resized_roi\n",
    "\n",
    "# カメラの指定\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # グレースケール画像に変換\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 顔を検出\n",
    "    faces = face_detector(gray)\n",
    "    \n",
    "    for face in faces:\n",
    "        # 顔のランドマークを取得\n",
    "        landmarks = landmark_predictor(gray, face)\n",
    "\n",
    "        # --- 各領域の分割処理 ---\n",
    "\n",
    "        # 1. 目の領域の処理（目を大きくする）\n",
    "        left_eye_points = np.array([(landmarks.part(n).x, landmarks.part(n).y) for n in range(36, 42)])\n",
    "        right_eye_points = np.array([(landmarks.part(n).x, landmarks.part(n).y) for n in range(42, 48)])\n",
    "\n",
    "        # 左目の領域を抽出し拡大\n",
    "        left_eye_rect = cv2.boundingRect(left_eye_points)\n",
    "        x, y, w, h = left_eye_rect\n",
    "        left_eye_roi = frame[y:y + h, x:x + w]\n",
    "        big_left_eye = apply_transformation(left_eye_roi, fx=1.2, fy=1.2)  # 目を1.2倍に拡大\n",
    "        new_height, new_width = big_left_eye.shape[:2]\n",
    "        frame[y:y + new_height, x:x + new_width] = big_left_eye\n",
    "\n",
    "        # 右目の領域を抽出し拡大\n",
    "        right_eye_rect = cv2.boundingRect(right_eye_points)\n",
    "        x, y, w, h = right_eye_rect\n",
    "        right_eye_roi = frame[y:y + h, x:x + w]\n",
    "        big_right_eye = apply_transformation(right_eye_roi, fx=1.2, fy=1.2)  # 目を1.2倍に拡大\n",
    "        new_height, new_width = big_right_eye.shape[:2]\n",
    "        frame[y:y + new_height, x:x + new_width] = big_right_eye\n",
    "\n",
    "        # 2. 鼻の領域の処理（鼻を高くする）\n",
    "        nose_points = np.array([(landmarks.part(n).x, landmarks.part(n).y) for n in range(27, 36)])\n",
    "        nose_rect = cv2.boundingRect(nose_points)\n",
    "        x, y, w, h = nose_rect\n",
    "        nose_roi = frame[y:y + h, x:x + w]\n",
    "        high_nose = apply_transformation(nose_roi, fx=1.0, fy=1.2)  # 縦方向に1.2倍に拡大\n",
    "        new_height, new_width = high_nose.shape[:2]\n",
    "        frame[y:y + new_height, x:x + new_width] = high_nose\n",
    "\n",
    "        # 3. 口の領域の処理（口を強調する）\n",
    "        mouth_points = np.array([(landmarks.part(n).x, landmarks.part(n).y) for n in range(48, 60)])\n",
    "        mouth_rect = cv2.boundingRect(mouth_points)\n",
    "        x, y, w, h = mouth_rect\n",
    "        mouth_roi = frame[y:y + h, x:x + w]\n",
    "        big_mouth = apply_transformation(mouth_roi, fx=1.2, fy=1.2)  # 口を1.2倍に拡大\n",
    "        new_height, new_width = big_mouth.shape[:2]\n",
    "        frame[y:y + new_height, x:x + new_width] = big_mouth\n",
    "\n",
    "    # フレームを表示\n",
    "    cv2.imshow('Feature-based Face Modification', frame)\n",
    "\n",
    "    # 'q'キーで終了\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 終了処理\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc6dbf0b-42cb-4d29-b9fb-cd9e43026f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "スタートボタンが押されました！\n",
      "撮影まで: 5秒\n",
      "撮影まで: 4秒\n",
      "撮影まで: 3秒\n",
      "撮影まで: 2秒\n",
      "撮影まで: 1秒\n",
      "シャッター音が再生されました\n",
      "画像が保存されました: photo_20241001_163651.png\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import time\n",
    "import os\n",
    "\n",
    "# DNNベースの顔検出器のロード\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "landmark_predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "# カウントダウン秒数\n",
    "COUNTDOWN_SECONDS = 5\n",
    "\n",
    "# カメラの指定\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# シャッター音の再生（OpenCVは音を扱えないため、winsoundやpygameを使用するか、代わりに効果音を表示）\n",
    "def play_shutter_sound():\n",
    "    # ここでシャッター音を再生するロジックを追加します\n",
    "    # pygame.mixerなどを使ってシャッター音ファイルを再生することが可能です\n",
    "    print(\"シャッター音が再生されました\")  # 実際には音を再生します\n",
    "\n",
    "# スタートボタンが押されると、カウントダウンを開始\n",
    "def start_countdown():\n",
    "    print(\"スタートボタンが押されました！\")\n",
    "    for i in range(COUNTDOWN_SECONDS, 0, -1):\n",
    "        print(f\"撮影まで: {i}秒\")\n",
    "        time.sleep(1)\n",
    "\n",
    "# 画像を保存する関数\n",
    "def save_image(frame):\n",
    "    filename = f'photo_{time.strftime(\"%Y%m%d_%H%M%S\")}.png'\n",
    "    cv2.imwrite(filename, frame)\n",
    "    print(f\"画像が保存されました: {filename}\")\n",
    "\n",
    "# メインループ\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # グレースケール画像に変換\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 顔を検出\n",
    "    faces = face_detector(gray)\n",
    "    \n",
    "    # 検出された顔にランドマークを描画（例: 目や口）\n",
    "    for face in faces:\n",
    "        landmarks = landmark_predictor(gray, face)\n",
    "        for n in range(68):\n",
    "            x = landmarks.part(n).x\n",
    "            y = landmarks.part(n).y\n",
    "            cv2.circle(frame, (x, y), 2, (255, 0, 0), -1)\n",
    "\n",
    "    # フレームを表示\n",
    "    cv2.imshow('Preview', frame)\n",
    "\n",
    "    # 's'キーでスタートボタンの役割\n",
    "    if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "        # スタートボタンを押すとカウントダウン開始\n",
    "        start_countdown()\n",
    "\n",
    "        # カウントダウンが終わったらシャッター音を再生し、写真を保存\n",
    "        play_shutter_sound()\n",
    "        save_image(frame)\n",
    "\n",
    "    # 'q'キーで終了\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 終了処理\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42782ad-a656-430d-a97e-6e699499ffcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
